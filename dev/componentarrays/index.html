<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Using ComponentArrays · MarginalLogDensities.jl</title><meta name="title" content="Using ComponentArrays · MarginalLogDensities.jl"/><meta property="og:title" content="Using ComponentArrays · MarginalLogDensities.jl"/><meta property="twitter:title" content="Using ComponentArrays · MarginalLogDensities.jl"/><meta name="description" content="Documentation for MarginalLogDensities.jl."/><meta property="og:description" content="Documentation for MarginalLogDensities.jl."/><meta property="twitter:description" content="Documentation for MarginalLogDensities.jl."/><meta property="og:url" content="https://ElOceanografo.github.io/MarginalLogDensities.jl/componentarrays/"/><meta property="twitter:url" content="https://ElOceanografo.github.io/MarginalLogDensities.jl/componentarrays/"/><link rel="canonical" href="https://ElOceanografo.github.io/MarginalLogDensities.jl/componentarrays/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">MarginalLogDensities.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Getting started</a></li><li><span class="tocitem">User guide</span><ul><li><a class="tocitem" href="../theory/">Theory</a></li><li><a class="tocitem" href="../sparse_ad/">Sparsity and AD</a></li><li><a class="tocitem" href="../tips/">Tips for success</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../hreg/">Hierarchical regression</a></li><li class="is-active"><a class="tocitem" href>Using ComponentArrays</a></li><li><a class="tocitem" href="../turing/">Turing integration</a></li></ul></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Using ComponentArrays</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Using ComponentArrays</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ElOceanografo/MarginalLogDensities.jl/blob/master/docs/src/componentarrays.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Making-life-easier-with-ComponentArrays"><a class="docs-heading-anchor" href="#Making-life-easier-with-ComponentArrays">Making life easier with ComponentArrays</a><a id="Making-life-easier-with-ComponentArrays-1"></a><a class="docs-heading-anchor-permalink" href="#Making-life-easier-with-ComponentArrays" title="Permalink"></a></h1><p>MarginalLogDensities requires you to write your log-density as a function of a single flat array of parameters, <code>u</code>. This makes the internal marginalization calculations easier to perform, but as your model becomes more complex, it becomes more annoying and error-prone to keep track of which indices in <code>u</code> refer to which variables inside your model. One  solution to this problem is provided in <a href="https://github.com/SciML/ComponentArrays.jl/tree/main">ComponentArrays.jl</a>, from the SciML ecosystem.</p><p>A <code>ComponentArray</code> is a type that behaves like an ordinary <code>Array</code>, but organized into  blocks that can be accessed via named indices:</p><pre><code class="language-julia-repl hljs">kjulia&gt; using ComponentArrays

julia&gt; u = ComponentArray(a = 5.0, b = [-0.1, 4.8])
ComponentVector{Float64}(a = 5.0, b = [-0.1, 4.8])

julia&gt; u.a
5.0

julia&gt; u.b
2-element view(::Vector{Float64}, 2:3) with eltype Float64:
 -0.1
  4.8

julia&gt; ones(3,3) * u # behaves like a normal vector
3-element Vector{Float64}:
 9.7
 9.7
 9.7</code></pre><p>If you define your parameters as a <code>ComponentVector</code>, working with them inside your log-density function becomes much easier, without introducing any computational overhead.</p><p>MarginalLogDensities works with <code>ComponentVectors</code> as well: instead of specifying the  integer indices of the variables to marginalize, you can give <code>Symbol</code>s referring to  blocks of the parameter vector.</p><p>To illustrate this, we&#39;ll fit a state-space model to some simulated time-series data. Specifically, we will have a two-dimensional vector autoregressive process, where the  hidden state <span>$\mathbf{x}$</span> evolves according to </p><p class="math-container">\[\begin{aligned}
\mathbf{x}_t &amp;= A \mathbf{x}_{t-1} + \mathbf{\epsilon}_t \\
\mathbf{\epsilon} $\sim \mathrm{MvNormal}(0, b^2 I)
\end{aligned}\]</p><p>where <span>$A$</span> is a square matrix and <span>$mathbf{\epsilon}$</span> is the process noise, with standard  deviation <span>$b$</span>. Out data, <span>$\mathbf{y}_t$</span>, are centered on <span>$\mathbf{y}_t$</span>, plus some  Gaussian noise with standard deviation <span>$c$</span>.</p><p class="math-container">\[\mathbf{y}_t \sim \mathrm{MvNormal(\mathbf{x}_t, c^2 I)}\]</p><p>We&#39;ll assume we know <span>$c$</span> a priori, but would like to estimate the transition matrix <span>$A$</span>  and the process noise <span>$b$</span>, while integrating out the unobserved states <span>$\mathbf{x}_t$</span> for  all times <span>$t$</span>. </p><p>Simulating and plotting our time series and observations:</p><pre><code class="language-julia hljs">using MarginalLogDensities
using ComponentArrays
using Distributions
import ReverseDiff
using Optimization, OptimizationOptimJL
using StatsPlots
using LinearAlgebra
using Random

Random.seed!(1234)

A = [0.8 -0.2;
    -0.1  0.5]
b = 0.3
c = 0.1

x = zeros(2, n)
for i in 2:n
    x[:, i] = A * x[:, i-1] + b * randn(2)
end
y = x .+ c .* randn.()

plot(x&#39;, layout=(2,1), legend=false, ylabel=[&quot;x1&quot; &quot;x2&quot;], xlabel=[&quot;&quot; &quot;Time&quot;])
scatter!(y&#39;, markersize=2, markerstrokewidth=0)</code></pre><img src="b872f56b.svg" alt="Example block output"/><p>Next, we define our log-density function. Note how we unpack the parameters using dot- notation, e.g. <code>log_b = u.log_b</code> (where <code>log_b</code> is a scalar) and <code>A = u.A</code> (where <code>A</code> is a vector).</p><p>The parameters for the variances <code>b</code> and <code>c</code> are supplied in the log-domain and <code>exp</code>- transformed to make sure they&#39;re always positive inside the model.</p><pre><code class="language-julia hljs">function logdensity(u, data)
    A = u.A
    b = exp(u.log_b)
    x  = u.x

    y = data.y
    n = data.n
    c  = data.c

    # Prior on initial state
    ll = logpdf(MvNormal(zeros(2), 10), x[:, 1])
    # first observation
    ll += logpdf(MvNormal(x[:, 1], c), y[:, 1])
    # rest of time series
    for t in 2:n
        ll += logpdf(MvNormal(A * x[:, t-1], b), x[:, t])
        ll += logpdf(MvNormal(x[:, t], c), y[:, t])
    end
    return ll
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">logdensity (generic function with 1 method)</code></pre><p>The inital value for our parameter vector is constructed as a <code>ComponentArray</code> to make it compatible with <code>logdensity</code> as it&#39;s written. The fixed <code>data</code> are a <code>NamedTuple</code>. These  are passed to the <code>MarginalLogDensity</code> constructor along with the function, as usual.</p><pre><code class="language-julia hljs">u0 = ComponentArray(
    A = A,
    log_b = 0,
    x = ones(2, n)
)
data = (y = y, n = n, c = c)
joint_vars = [:A, :log_b]

mld = MarginalLogDensity(logdensity, u0, [:x], data,
    LaplaceApprox(adtype=AutoReverseDiff()), sparsity_detector=TracerSparsityDetector())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">MarginalLogDensity of function Main.logdensity
Integrating 600/605 variables via LaplaceApprox</code></pre><p>However, we&#39;ve specified we want to integrate out the latent states <code>x</code> as a  random effect: we just pass a <code>Vector</code> containing the symbol(s) of the variables to  marginalize.</p><div class="admonition is-info" id="Note-35b9028d4731ac4b"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-35b9028d4731ac4b" title="Permalink"></a></header><div class="admonition-body"><p>We specify the ReverseDiff AD backend to use for gradients inside the <code>LaplaceApproximation</code> method. Since our marginal variables are fairly high dimensional  (a 1D latent state times 300 time steps gives 600 marginal parameters), reverse-mode AD is much faster than the default ForwardDiff backend. See the page on sparse automatic  differentiation for more info.</p></div></div><p>From here, we select the subset of <code>u0</code> containing the non-marginal variables, set up an optimization problem based on <code>mld</code>, and solve it.</p><pre><code class="language-julia hljs">joint_vars = [:A, :log_b]
v0 = u0[joint_vars]
func = OptimizationFunction(mld);
prob = OptimizationProblem(func, v0, data)
sol = solve(prob, NelderMead())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">retcode: Success
u: ComponentVector{Float64}(A = [0.8165592058698792 -0.16052425572840753; -0.09169494882181824 0.409545384809097], log_b = -1.0912549637868727)</code></pre><p>We can use the delta method (based on finite differences) to estimate standard errors for our time-series parameters.</p><pre><code class="language-julia hljs">estimates = sol.u
std_err = 1.96 ./ sqrt.(diag(hessian(v -&gt; -mld(v), AutoFiniteDiff(), sol.u)))
scatter(Vector(sol.u), yerr = std_err, label=&quot;Fitted&quot;,
    xticks=(1:5, [&quot;A[1,1]&quot;, &quot;A[1,2]&quot;, &quot;A[2,1]&quot;, &quot;A[2,2]&quot;, &quot;log_b&quot;]))
scatter!([vec(A); log(b)], label=&quot;True value&quot;)</code></pre><img src="40bacff8.svg" alt="Example block output"/><p>The plot shows that they match up fairly well with the true values.</p><p>We can also access the latest value of the latent state, conditional on these point  estimates:</p><pre><code class="language-julia hljs">mld(sol.u)
x_hat = cached_params(mld).x
x_err = 1.96 ./ sqrt.(diag(cached_hessian(mld)))

plot(x_hat&#39;, ribbon=x_err&#39;, label=&quot;Estimated state ± 2 s.d.&quot;, layout=(2, 1), color=3)
plot!(x&#39;, label=&quot;Latent state&quot;, xlabel=&quot;Time step&quot;, color=1)
scatter!(y&#39;, label=&quot;Noisy observations&quot;, markerstrokewidth=0, markersize=2, color=2)</code></pre><img src="c81ef860.svg" alt="Example block output"/></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../hreg/">« Hierarchical regression</a><a class="docs-footer-nextpage" href="../turing/">Turing integration »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Tuesday 21 October 2025 00:28">Tuesday 21 October 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
