<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · MarginalLogDensities.jl</title><meta name="title" content="Home · MarginalLogDensities.jl"/><meta property="og:title" content="Home · MarginalLogDensities.jl"/><meta property="twitter:title" content="Home · MarginalLogDensities.jl"/><meta name="description" content="Documentation for MarginalLogDensities.jl."/><meta property="og:description" content="Documentation for MarginalLogDensities.jl."/><meta property="twitter:description" content="Documentation for MarginalLogDensities.jl."/><meta property="og:url" content="https://ElOceanografo.github.io/MarginalLogDensities.jl/"/><meta property="twitter:url" content="https://ElOceanografo.github.io/MarginalLogDensities.jl/"/><link rel="canonical" href="https://ElOceanografo.github.io/MarginalLogDensities.jl/"/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>MarginalLogDensities.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Basic-tutorial"><span>Basic tutorial</span></a></li><li><a class="tocitem" href="#How-it-works"><span>How it works</span></a></li><li><a class="tocitem" href="#A-more-realistic-example:-hierarchical-regression"><span>A more realistic example: hierarchical regression</span></a></li><li><a class="tocitem" href="#Using-ComponentArrays"><span>Using ComponentArrays</span></a></li><li><a class="tocitem" href="#Turing.jl-integration"><span>Turing.jl integration</span></a></li><li><a class="tocitem" href="#Performance:-Sparsity-and-AD"><span>Performance: Sparsity and AD</span></a></li><li><a class="tocitem" href="#API"><span>API</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ElOceanografo/MarginalLogDensities.jl/blob/master/docs/src/index.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="MarginalLogDensities.jl"><a class="docs-heading-anchor" href="#MarginalLogDensities.jl">MarginalLogDensities.jl</a><a id="MarginalLogDensities.jl-1"></a><a class="docs-heading-anchor-permalink" href="#MarginalLogDensities.jl" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>This package implements tools for integrating out (marginalizing) parameters from log-probability functions, such as likelihoods and posteriors of statistical models. This approach is useful for fitting models that incorporate random effects or  latent variables that are important for structuring the model, but whose exact  values may not be of interest in and of themselves. In the language of regression,  these are known as &quot;random effects,&quot; and in other contexts, they may be called &quot;nuisance parameters.&quot; Whatever they are called, we hope that our log-density function can be optimized faster and/or more reliably if we focus on the parameters we are <em>actually</em> interested in, averaging the log-density over all possible values of  the ones we are not.</p><h3 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h3><p>MarginalLogDensities (MLD for short) requires Julia v1.10 or greater. It is a registered Julia package, so you can install it from the REPL by typing <code>]</code> to enter package-manager mode, then running</p><pre><code class="language-julia-repl hljs">pkg&gt; add MarginalLogDensities</code></pre><h2 id="Basic-tutorial"><a class="docs-heading-anchor" href="#Basic-tutorial">Basic tutorial</a><a id="Basic-tutorial-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-tutorial" title="Permalink"></a></h2><p>A basic example follows. We start out by writing a function for our target log- density. This function must have the signature <code>f(u, data)</code>, where <code>u</code> is a numeric vector of parameters and <code>data</code> contains any data, or fixed parameters, needed by the function.  The <code>data</code> argument can be anything you&#39;d like, such as a <code>Vector</code>, <code>NamedTuple</code>, <code>DataFrame</code>, or some other <code>struct</code>. (If your function does not depend on any external data, just ignore that argument in the function body)</p><div class="admonition is-info" id="Note-c71517f39ad81d7f"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-c71517f39ad81d7f" title="Permalink"></a></header><div class="admonition-body"><p>Note that the convention for this package is to write the function as a <strong>positive</strong> log-density.</p></div></div><pre><code class="language-julia hljs">using MarginalLogDensities, Distributions, LinearAlgebra

N = 3
σ = 1.5
dist = MvNormal(σ^2 * I(3))
data = (N=N, dist=dist)

function logdensity(u, data)
   return logpdf(data.dist, u) 
end</code></pre><p>We then set up a marginalized version of this function. First, we set an initial value for our parameter vector <code>u</code>, as well as a set of indices <code>iw</code> indicating the subset of <code>u</code> that we want to integrate out. </p><pre><code class="language-julia hljs">u = [1.1, -0.3, 0.1] # arbitrary initial values
iw = [1, 3]</code></pre><p>We create the marginalized version of the function by calling the <code>MarginalLogDensity</code> constructor with the original function <code>logdensity</code>, the full parameter vector <code>u</code>, the indices of the marginalized values <code>iw</code>, and the <code>data</code>. (If your function does not depend on the <code>data</code> argument, it can be omitted here.)</p><pre><code class="language-julia hljs">marginal_logdensity = MarginalLogDensity(logdensity, u, iw, data)</code></pre><p>Here, we are saying that we want to calculate <code>logdensity</code> as a function of <code>u[2]</code> only,  while integrating over all possible values of <code>u[1]</code> and <code>u[3]</code>. In the laguage of  mathematics, if we write <code>u -&gt; logdensity(u, data)</code> as <span>$f(u)$</span>, then the marginalized  function <code>v -&gt; marginal_logdensity(v, data)</code> is calculating</p><p class="math-container">\[f_m(u_2) = \iint f(u) \; du_1 du_3.\]</p><p>After defining <code>marginal_logdensity</code>, you can call it just like the original function, with the difference that you only need to supply <code>v</code>, the subset of parameters you&#39;re  interested in, rather than the entire set <code>u</code>. </p><pre><code class="language-julia hljs">initial_v = [1.0] # another arbitrary starting value
length(initial_v) == N - length(iw) # true
marginal_logdensity(initial_v, data)
# -1.5466258635350596</code></pre><p>Compare this value to the analytic marginal density, i.e. the log-probability of <span>$N(0, 1.5)$</span> at 1.0:</p><pre><code class="language-julia hljs">logpdf(Normal(0, 1.5), 1.0)
# -1.5466258635350594</code></pre><p>The point of doing all this was to find an optimal set of parameters <code>v</code> for your data. This package includes an interface to Optimization.jl that  works directly with a <code>MarginalLogDensity</code> object, making  optimization easy. The simplest way is to construct an <code>OptimizationProblem</code> directly from the <code>MarginalLogDensity</code> and <code>solve</code> it:</p><pre><code class="language-julia hljs">using Optimization, OptimizationOptimJL

opt_problem = OptimizationProblem(marginal_logdensity, v0)
opt_solution = solve(opt_problem, NelderMead())</code></pre><p>If you want more control over options, for instance setting an AD backend, you can construct an <code>OptimizationFunction</code> explicitly:</p><pre><code class="language-julia hljs">opt_function = OptimizationFunction(marginal_logdensity, AutoFiniteDiff())
opt_problem = OptimizationProblem(opt_function, v0)
opt_solution = solve(opt_problem, LBFGS())</code></pre><p>Note that at present we can&#39;t differentiate through the Laplace approximation, so outer  optimizations like this need to either use a gradient-free solver (like <code>NelderMead()</code>), or a finite-difference backend (like <code>AutoFiniteDiff()</code>). This is on the list of planned improvements.</p><h2 id="How-it-works"><a class="docs-heading-anchor" href="#How-it-works">How it works</a><a id="How-it-works-1"></a><a class="docs-heading-anchor-permalink" href="#How-it-works" title="Permalink"></a></h2><p>By default, this package uses Laplace&#39;s method to approximate this integral. The Laplace approximation is fast in high dimensions, and works well for log-densities that are approximately Gaussian. The marginalization can also be done via numerical integration, a.k.a. cubature, which may be more accurate but will not scale well for higher dimensional problems. You can choose which marginalizer to use by passing the appropriate <code>AbstractMarginalizer</code> to <code>MarginalLogDensity</code>:</p><pre><code class="language-julia hljs">MarginalLogDensity(logdensity, u, iw, data, Cubature())
MarginalLogDensity(logdensity, u, iw, data, LaplaceApprox())</code></pre><p>Both <code>Cubature()</code> and <code>LaplaceApprox()</code> can be specified with various options; refer to their  docstrings for details.</p><p>&lt;!– You also can re-run the same  <code>MarginalLogDensity</code> with different <code>data</code> if you want (though if you&#39;re depending on  the sparsity of your changing the <code>data</code> causes the sparsity). –&gt;</p><h2 id="A-more-realistic-example:-hierarchical-regression"><a class="docs-heading-anchor" href="#A-more-realistic-example:-hierarchical-regression">A more realistic example: hierarchical regression</a><a id="A-more-realistic-example:-hierarchical-regression-1"></a><a class="docs-heading-anchor-permalink" href="#A-more-realistic-example:-hierarchical-regression" title="Permalink"></a></h2><p>Let&#39;s show how to use MLD on a slightly more complex problem, similar to one you might actually encounter in practice: a hierarchical linear regression. Our response variable  <span>$y$</span> is a linear function of the predictor <span>$x$</span> plus some normally-distributed noise.  Our data are divided into 50 different groups, and each group <span>$i$</span> has its own intercept term <span>$a_i$</span>. These intercepts are in turn drawn from a normal distribution with mean <span>$\mu_0$</span> and standard deviation <span>$\sigma_0$</span>.</p><p class="math-container">\[\begin{aligned}
\mu_{i, j} &amp;= a_i + b x_{i,j} \\
y_{i,j} &amp;\sim \mathrm{Normal}(\mu_{i, j}, \sigma) \\
a_i &amp;\sim \mathrm{Normal}(\mu_0, \sigma_0)
\end{aligned}\]</p><p>Where <span>$i$</span> indexes the categories and <span>$j$</span> indexes the individual data points.</p><p>Choosing values for these parameters and simulating a dataset yields the following plot:</p><pre><code class="language-julia hljs">using MarginalLogDensities
using Distributions
using StatsPlots
using Random

Random.seed!(123)
ncategories = 50
points_per_category = 5
categories = 1:ncategories
μ0 = 5.0
σ0 = 5.0
aa = rand(Normal(μ0, σ0), ncategories)
b = 4.5
σ = 1.5
category = repeat(categories, inner=points_per_category)
n = length(category)
x = rand(Uniform(-1, 1), n)
μ = [aa[category[i]] + b * x[i] for i in 1:n]
y = rand.(Normal.(μ, σ))

scatter(x, y, color=category, legend=false, xlabel=&quot;x&quot;, ylabel=&quot;y&quot;)</code></pre><img src="index-cc13c9ba.svg" alt="Example block output"/><p>Given this model structure, we can write a function for the log-likelihood of the data,  conditional on a vector of parameters <code>u</code>. The function is written so that <code>u</code> is  unbounded, that is, there are no constraints on any of its elements. This means it needs to include <code>exp</code> transformations for the elements of <code>u</code> corresponding to<code>σ0</code> and <code>σ</code> to make sure they end up non-negative inside the model.</p><pre><code class="language-julia hljs">function loglik(u, data)
    # unpack the parameters
    μ0 = u[1]
    σ0 = exp(u[2])
    σ = exp(u[3])
    b = u[4]
    aa = u[5:end]
    # predict the data
    μ = [aa[data.category[i]] + b * data.x[i] for i in 1:data.n]
    # calculate and return the log-likelihood
    return loglikelihood(Normal(μ0, σ0), aa) + sum(logpdf.(Normal.(μ, σ), data.y))
end

data = (; x, y, category, n)
u0 = randn(4 + ncategories) # μ0, σ0, σ, b, and aa
loglik(u0, data)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">-76817.8609526664</code></pre><p>Say that we&#39;re not particularly interested in the individual intercepts <span>$a_i$</span>, but want to do inference on the other parameters. One way to approach this is to marginalize them</p><pre><code class="language-julia hljs"># select variables of interest out of complete parameter vector
iv = 1:4
v0 = u0[iv]

# indices of nuisance parameters: everything esle
iw = setdiff(eachindex(u0), iv)

# construct a MarginalLogDensity
mld = MarginalLogDensity(loglik, u0, iw, data)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">MarginalLogDensity of function Main.loglik
Integrating 50/54 variables via LaplaceApprox</code></pre><p>We can then call <code>mld</code> like a function:</p><pre><code class="language-julia hljs">mld(v0)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">-7365.51654503446</code></pre><p>And, using Optimization.jl, estimate the maximum marginal-likelihood values of our four parameters of interest:</p><pre><code class="language-julia hljs">using Optimization, OptimizationOptimJL

opt_func = OptimizationFunction(mld)
opt_prob = OptimizationProblem(opt_func, v0, data)
opt_sol = solve(opt_prob, NelderMead())

μ0_opt, logσ0_opt, logσ_opt, b_opt = opt_sol.u

println(&quot;Estimated μ0:  $(round(μ0_opt, digits=2))  (true value $(μ0))&quot;)
println(&quot;Estimated σ0:  $(round(exp(logσ0_opt), digits=2))  (true value $(σ0))&quot;)
println(&quot;Estimated b:   $(round(b_opt, digits=2))  (true value $(b))&quot;)
println(&quot;Estimated σ:   $(round(exp(logσ_opt), digits=2))   (true value $(σ))&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Estimated μ0:  4.46  (true value 5.0)
Estimated σ0:  5.18  (true value 5.0)
Estimated b:   3.78  (true value 4.5)
Estimated σ:   1.8   (true value 1.5)</code></pre><h2 id="Using-ComponentArrays"><a class="docs-heading-anchor" href="#Using-ComponentArrays">Using ComponentArrays</a><a id="Using-ComponentArrays-1"></a><a class="docs-heading-anchor-permalink" href="#Using-ComponentArrays" title="Permalink"></a></h2><h2 id="Turing.jl-integration"><a class="docs-heading-anchor" href="#Turing.jl-integration">Turing.jl integration</a><a id="Turing.jl-integration-1"></a><a class="docs-heading-anchor-permalink" href="#Turing.jl-integration" title="Permalink"></a></h2><h2 id="Performance:-Sparsity-and-AD"><a class="docs-heading-anchor" href="#Performance:-Sparsity-and-AD">Performance: Sparsity and AD</a><a id="Performance:-Sparsity-and-AD-1"></a><a class="docs-heading-anchor-permalink" href="#Performance:-Sparsity-and-AD" title="Permalink"></a></h2><h2 id="API"><a class="docs-heading-anchor" href="#API">API</a><a id="API-1"></a><a class="docs-heading-anchor-permalink" href="#API" title="Permalink"></a></h2><ul><li><a href="#MarginalLogDensities.Cubature"><code>MarginalLogDensities.Cubature</code></a></li><li><a href="#MarginalLogDensities.LaplaceApprox"><code>MarginalLogDensities.LaplaceApprox</code></a></li><li><a href="#MarginalLogDensities.MarginalLogDensity"><code>MarginalLogDensities.MarginalLogDensity</code></a></li><li><a href="#MarginalLogDensities.cached_hessian-Tuple{MarginalLogDensity}"><code>MarginalLogDensities.cached_hessian</code></a></li><li><a href="#MarginalLogDensities.cached_params-Tuple{MarginalLogDensity}"><code>MarginalLogDensities.cached_params</code></a></li><li><a href="#MarginalLogDensities.ijoint-Tuple{MarginalLogDensity}"><code>MarginalLogDensities.ijoint</code></a></li><li><a href="#MarginalLogDensities.imarginal-Tuple{MarginalLogDensity}"><code>MarginalLogDensities.imarginal</code></a></li><li><a href="#MarginalLogDensities.merge_parameters-Union{Tuple{T2}, Tuple{T1}, Tuple{AbstractVector{T1}, AbstractVector{T2}, Any, Any, Any}} where {T1, T2}"><code>MarginalLogDensities.merge_parameters</code></a></li><li><a href="#MarginalLogDensities.nfull-Tuple{MarginalLogDensity}"><code>MarginalLogDensities.nfull</code></a></li><li><a href="#MarginalLogDensities.njoint-Tuple{MarginalLogDensity}"><code>MarginalLogDensities.njoint</code></a></li><li><a href="#MarginalLogDensities.nmarginal-Tuple{MarginalLogDensity}"><code>MarginalLogDensities.nmarginal</code></a></li><li><a href="#MarginalLogDensities.split_parameters-Tuple{Any, Any, Any}"><code>MarginalLogDensities.split_parameters</code></a></li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MarginalLogDensities.Cubature" href="#MarginalLogDensities.Cubature"><code>MarginalLogDensities.Cubature</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Cubature([; solver=LBFGS(), adtype=AutoForwardDiff(), upper=nothing, lower=nothing, nσ=6; opt_func_kwargs...])</code></pre><p>Construct a <code>Cubature</code> marginalizer to integrate out marginal variables via numerical integration (a.k.a. cubature).</p><p>If explicit upper and lower bounds for the integration are not supplied, this marginalizer will attempt to select good ones by first optimizing the marginal variables, doing a  Laplace approximation at their mode, and then going <code>nσ</code> standard deviations away on either side, assuming approximate normality.</p><p>The integration is performed using <code>hcubature</code> from Cubature.jl.</p><p><strong>Arguments</strong></p><ul><li><code>solver=LBFGS()</code> : Algorithm to use when performing the inner optimization to find the</li></ul><p>mode of the marginalized variables. Can be any algorithm defined in Optim.jl.</p><ul><li><code>adtype=AutoForwardDiff()</code> : Automatic differentiation type to use for the </li></ul><p>inner optimization. <code>AutoForwardDiff()</code> is robust and fast for small problems; for larger ones <code>AutoReverseDiff()</code> or <code>AutoZygote()</code> are likely better.</p><ul><li><code>upper</code>, <code>lower</code> : Optional upper and lower bounds for the numerical integration. If</li></ul><p>supplied, they must be numeric vectors the same length as the marginal variables.</p><ul><li><code>nσ=6.0</code> : If <code>upper</code> and <code>lower</code> are not supplied, integrate this many standard</li></ul><p>deviations away from the mode based on a Laplace approximation to the curvature at that  point.</p><ul><li><code>opt_func_kwargs</code> : Optional keyword arguments passed on to</li></ul><p><code>Optimization.OptimizationFunction</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ElOceanografo/MarginalLogDensities.jl/blob/0860b2359004403286cd33f6a38b4918f4b9603e/src/MarginalLogDensities.jl#L64-L90">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MarginalLogDensities.LaplaceApprox" href="#MarginalLogDensities.LaplaceApprox"><code>MarginalLogDensities.LaplaceApprox</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LaplaceApprox([solver=LBFGS() [; adtype=AutoForwardDiff(), opt_func_kwargs...]])</code></pre><p>Construct a <code>LaplaceApprox</code> marginalizer to integrate out marginal variables via the Laplace approximation. This method will usually be faster than <code>Cubature</code>, especially in high dimensions, though it may not be as accurate.</p><p><strong>Arguments</strong></p><ul><li><code>solver=LBFGS()</code> : Algorithm to use when performing the inner optimization to find the</li></ul><p>mode of the marginalized variables. Can be any algorithm defined in Optim.jl.</p><ul><li><code>adtype=AutoForwardDiff()</code> : Automatic differentiation type to use for the inner</li></ul><p>optimization, specified via the ADTypes.jl interface. <code>AutoForwardDiff()</code> is robust and fast for small problems; for larger ones <code>AutoReverseDiff()</code> or <code>AutoZygote()</code> are likely better.</p><ul><li><code>opt_func_kwargs</code> : Optional keyword arguments passed on to</li></ul><p><code>Optimization.OptimizationFunction</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ElOceanografo/MarginalLogDensities.jl/blob/0860b2359004403286cd33f6a38b4918f4b9603e/src/MarginalLogDensities.jl#L36-L52">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MarginalLogDensities.MarginalLogDensity" href="#MarginalLogDensities.MarginalLogDensity"><code>MarginalLogDensities.MarginalLogDensity</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MarginalLogDensity(logdensity, u, iw, data, [method=LaplaceApprox(); 
[hess_adtype=nothing, sparsity_detector=DenseSparsityDetector(method.adtype, atol=cbrt(eps())),
coloring_algorithm=GreedyColoringAlgorithm()]])</code></pre><p>Construct a callable object which wraps the function <code>logdensity</code> and integrates over a subset of its arguments.</p><p>The resulting <code>MarginalLogDensity</code> object  <code>mld</code> can then be called like a function as <code>mld(v, data)</code>, where <code>v</code> is the subset of the full parameter vector <code>u</code> which is <em>not</em> indexed by <code>iw</code>.  If <code>length(u) == n</code> and <code>length(iw) == m</code>, then <code>length(v) == n-m</code>.</p><p><strong>Arguments</strong></p><ul><li><code>logdensity</code> : function with signature <code>(u, data)</code> returning a positive</li></ul><p>log-probability (e.g. a log-pdf, log-likelihood, or log-posterior). In this function, <code>u</code> is a vector of variable parameters and <code>data</code> is an object (Array, NamedTuple, or whatever) that contains data and/or fixed parameters.</p><ul><li><code>u</code> : Vector of initial values for the parameter vector.</li><li><code>iw</code> : Vector of indices indicating which elements of <code>u</code> should be marginalized.</li><li><code>data=()</code> : Optional argument</li><li><code>method</code> : How to perform the marginalization.  Defaults to <code>LaplaceApprox()</code>; <code>Cubature()</code></li></ul><p>is also available.</p><ul><li><code>hess_adtype = nothing</code> : Specifies how to calculate the Hessian of the marginalized </li></ul><p>variables. If not specified, defaults to a sparse second-order method using forward AD  over the AD type given in the <code>method</code> (<code>AutoForwardDiff()</code> is the default).  Other backends can be set by loading the appropriate AD package and using the ADTypes.jl  interface.</p><ul><li><code>sparsity_detector = DenseSparsityDetector(method.adtype, atol=cbrt(eps))</code> : How to</li></ul><p>perform the sparsity detection. Detecting sparsity takes some time and may not be worth it for small problems, but for larger problems it can be extremely worth it. The default  <code>DenseSparsityDetector</code> is most robust, but if it&#39;s too slow, or if you&#39;re running out of  memory on a larger problem, try the tracing-based dectectors from SparseConnectivityTracer.jl.</p><ul><li><code>coloring_algorithm = GreedyColoringAlgorithm()</code> : How to determine the matrix &quot;colors&quot;</li></ul><p>to compress the sparse Hessian.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using MarginalLogDensities, Distributions

julia&gt; N = 4

julia&gt; dist = MvNormal(I(3))

julia&gt; data = (N=N, dist=dist)

julia&gt; function logdensity(u, data) # arbitrary simple density function
           return logpdf(data.dist, u) 
       end

julia&gt; u0 = rand(N)

julia&gt; mld = MarginalLogDensity(logdensity, u0, [1, 3], data)

julia&gt; mld(rand(2), data)
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ElOceanografo/MarginalLogDensities.jl/blob/0860b2359004403286cd33f6a38b4918f4b9603e/src/MarginalLogDensities.jl#L106-L163">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MarginalLogDensities.cached_hessian-Tuple{MarginalLogDensity}" href="#MarginalLogDensities.cached_hessian-Tuple{MarginalLogDensity}"><code>MarginalLogDensities.cached_hessian</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Get the value of the cached Hessian matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ElOceanografo/MarginalLogDensities.jl/blob/0860b2359004403286cd33f6a38b4918f4b9603e/src/MarginalLogDensities.jl#L255">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MarginalLogDensities.cached_params-Tuple{MarginalLogDensity}" href="#MarginalLogDensities.cached_params-Tuple{MarginalLogDensity}"><code>MarginalLogDensities.cached_params</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Get the value of the cached parameter vector <code>u</code>. This includes the latest values given  for the non-marginalized variables <code>v</code>, as well as the modal values of the marginalized variables <code>w</code> conditional on <code>v</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ElOceanografo/MarginalLogDensities.jl/blob/0860b2359004403286cd33f6a38b4918f4b9603e/src/MarginalLogDensities.jl#L248-L252">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MarginalLogDensities.ijoint-Tuple{MarginalLogDensity}" href="#MarginalLogDensities.ijoint-Tuple{MarginalLogDensity}"><code>MarginalLogDensities.ijoint</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Return the indices of the non-marginalized variables, <code>iv</code>, in <code>u</code> </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ElOceanografo/MarginalLogDensities.jl/blob/0860b2359004403286cd33f6a38b4918f4b9603e/src/MarginalLogDensities.jl#L236">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MarginalLogDensities.imarginal-Tuple{MarginalLogDensity}" href="#MarginalLogDensities.imarginal-Tuple{MarginalLogDensity}"><code>MarginalLogDensities.imarginal</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Return the indices of the marginalized variables, <code>iw</code>, in <code>u</code> </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ElOceanografo/MarginalLogDensities.jl/blob/0860b2359004403286cd33f6a38b4918f4b9603e/src/MarginalLogDensities.jl#L233">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MarginalLogDensities.merge_parameters-Union{Tuple{T2}, Tuple{T1}, Tuple{AbstractVector{T1}, AbstractVector{T2}, Any, Any, Any}} where {T1, T2}" href="#MarginalLogDensities.merge_parameters-Union{Tuple{T2}, Tuple{T1}, Tuple{AbstractVector{T1}, AbstractVector{T2}, Any, Any, Any}} where {T1, T2}"><code>MarginalLogDensities.merge_parameters</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Splice together the estimated (fixed) parameters <code>v</code> and marginalized (random) parameters <code>w</code> into the single parameter vector <code>u</code>, based on their indices <code>iv</code> and <code>iw</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ElOceanografo/MarginalLogDensities.jl/blob/0860b2359004403286cd33f6a38b4918f4b9603e/src/MarginalLogDensities.jl#L266-L269">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MarginalLogDensities.nfull-Tuple{MarginalLogDensity}" href="#MarginalLogDensities.nfull-Tuple{MarginalLogDensity}"><code>MarginalLogDensities.nfull</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Return the full dimension of the marginalized function, i.e. <code>length(u)</code> </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ElOceanografo/MarginalLogDensities.jl/blob/0860b2359004403286cd33f6a38b4918f4b9603e/src/MarginalLogDensities.jl#L239">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MarginalLogDensities.njoint-Tuple{MarginalLogDensity}" href="#MarginalLogDensities.njoint-Tuple{MarginalLogDensity}"><code>MarginalLogDensities.njoint</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Return the number of non-marginalized variables.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ElOceanografo/MarginalLogDensities.jl/blob/0860b2359004403286cd33f6a38b4918f4b9603e/src/MarginalLogDensities.jl#L245">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MarginalLogDensities.nmarginal-Tuple{MarginalLogDensity}" href="#MarginalLogDensities.nmarginal-Tuple{MarginalLogDensity}"><code>MarginalLogDensities.nmarginal</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Return the number of marginalized variables.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ElOceanografo/MarginalLogDensities.jl/blob/0860b2359004403286cd33f6a38b4918f4b9603e/src/MarginalLogDensities.jl#L242">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MarginalLogDensities.split_parameters-Tuple{Any, Any, Any}" href="#MarginalLogDensities.split_parameters-Tuple{Any, Any, Any}"><code>MarginalLogDensities.split_parameters</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Split the vector of all parameters <code>u</code> into its estimated (fixed) components <code>v</code> and marginalized (random) components <code>w</code>, based on their indices <code>iv</code> and <code>iw</code>. components</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ElOceanografo/MarginalLogDensities.jl/blob/0860b2359004403286cd33f6a38b4918f4b9603e/src/MarginalLogDensities.jl#L289-L293">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Friday 19 September 2025 03:01">Friday 19 September 2025</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
